{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file contains useful utility functions that can be reused by others. \n",
    "## Please feel free to add more! :-)\n",
    "\n",
    "\n",
    "### To utilize the functions in this file:\n",
    "\n",
    "1. Install the [**nbimporter**](https://github.com/grst/nbimporter) package\n",
    "\n",
    "        pip install nbimporter\n",
    "\n",
    "2. Set-up your environment in the folder where you cloned this repository. Create a **.env** file with the following:\n",
    "\n",
    "        eruser=**replace with user**\n",
    "        erdatabase=**replace with database**\n",
    "        erpassword=**replace with password**\n",
    "        erhost=**replace with host**\n",
    "        erport=**replace with port**\n",
    "        \n",
    "3. Create a new iPython Notebook\n",
    "4. Import both **nbimporter** and **utilities** (this notebook)\n",
    "\n",
    "        import nbimporter\n",
    "        import utilities\n",
    "          \n",
    "5. To call a function in this notebook:\n",
    "   \n",
    "        utilities.your_function_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# connect to postgres\n",
    "def pgconnect():\n",
    "    try:\n",
    "        conn = psycopg2.connect(database=os.environ.get(\"erdatabase\"),\n",
    "                                user=os.environ.get(\"eruser\"),\n",
    "                                password = os.environ.get(\"erpassword\"),\n",
    "                                host=os.environ.get(\"erhost\"),\n",
    "                                port=os.environ.get(\"erport\"))\n",
    "        print(\"Opened database successfully\")\n",
    "        return conn\n",
    "    \n",
    "    except psycopg2.Error as e:\n",
    "        print(\"I am unable to connect to the database\")\n",
    "        print(e)\n",
    "        print(e.pgcode)\n",
    "        print(e.pgerror)\n",
    "        print(traceback.format_exc())\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pgquery(QUERY):\n",
    "    '''\n",
    "    takes SQL query string, opens a cursor, and executes query in psql\n",
    "    '''\n",
    "    conn = pgconnect()\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        print(\"SQL QUERY = \"+QUERY)\n",
    "        cur.execute(\"SET statement_timeout = 0\")\n",
    "        cur.execute(QUERY)\n",
    "        # Extract the column names and insert them in header\n",
    "        col_names = []\n",
    "        for elt in cur.description:\n",
    "            col_names.append(elt[0])    \n",
    "    \n",
    "        D = cur.fetchall() #convert query result to list\n",
    "        # Create the dataframe, passing in the list of col_names extracted from the description\n",
    "        conn.close()\n",
    "        return pd.DataFrame(D, columns=col_names)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e.pgerror)\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will return a reshaped dataframe that contains the following columns:\n",
    "#\n",
    "# incident_id | responderunit_id | responder_id | typenaturecode_id | fireblock | t1 | t2 |  ...\n",
    "# where t1, t2, ... , tn are the timedesc_id that we are looking for.\n",
    "#\n",
    "# usage: getTimeDataset(timedesc_dict)\n",
    "#\n",
    "# param: timedesc_dict - keys are the timedesc_ids you want\n",
    "#                      - values are the human descriptions for them \n",
    "# known issues: this eliminates \"responder_id\" (so we can probably just get rid of it in the query)\n",
    "#               responder_id values were inconsistent and strange, so I decided to just ignore them\n",
    "#               when doing anaylsis.\n",
    "def getTimeDataset(timedesc_dict):\n",
    "    RESPONSE_TIME_QUERY='''\n",
    "                        SELECT  I.incident_id, R.responderunit_id, T.responder_id,\n",
    "                                T.timedesc_id, I.typenaturecode_id, I.fireblock, I.fmarespcomp,\n",
    "                                T.realtime\n",
    "                        FROM incident as I\n",
    "                        INNER JOIN inctimes as T\n",
    "                                ON I.incident_id = T.incident_id\n",
    "                        INNER JOIN responder as R\n",
    "                                ON ( I.incident_id = R.incident_id AND T.responder_id = R.responder_id)\n",
    "                        WHERE T.timedesc_id IN ??TIMEDESC_IDS??\n",
    "                                AND T.responder_id IS NOT NULL;\n",
    "                        '''\n",
    "    \n",
    "    # add the timedesc_ids that we want to the query\n",
    "    timedesc_ids = str(tuple(timedesc_dict.keys())).replace(\"'\", \"\")\n",
    "    RESPONSE_TIME_QUERY = RESPONSE_TIME_QUERY.replace(\"??TIMEDESC_IDS??\", str(timedesc_ids))\n",
    "    \n",
    "    # execute the query: **this takes a pretty long time**\n",
    "    df = pgquery(RESPONSE_TIME_QUERY)\n",
    "    \n",
    "    # now reshape the data so that we can do analysis more easily. \n",
    "    table = df.pivot_table(index=['incident_id', 'responderunit_id', 'typenaturecode_id',\n",
    "                                  'fireblock', 'fmarespcomp'],\n",
    "                      columns='timedesc_id', values='realtime', aggfunc='first')\n",
    "    table.rename(columns=timedesc_dict, inplace=True)\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:data-science]",
   "language": "python",
   "name": "conda-env-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
